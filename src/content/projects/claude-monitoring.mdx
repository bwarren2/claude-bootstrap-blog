---
title: "Building a Real-Time Claude Code Monitoring Dashboard"
description: "A local observability stack — Prometheus, Grafana, Loki, and a custom JSONL watcher — that tracks cost, tokens, and tool usage across Claude Code sessions in real-time. Built in 50 minutes for ~$17."
pubDate: 2026-02-20
status: complete
difficulty: intermediate
ambitionRating: 4
techStack: ["TypeScript", "Docker Compose", "Grafana", "Prometheus", "Loki", "OpenTelemetry", "Node.js"]
projectType: "automation"
claudeTechniques: ["plan-mode", "scaffold-then-fill", "parallel-agents", "iterative-debugging"]
tags: ["monitoring", "observability", "grafana", "prometheus", "cost-tracking", "opentelemetry"]
heroImage: "/claude-bootstrap-blog/images/monitoring/01-cost-overview.png"
featured: true
readingOrder: 5
promptSnippets:
  - prompt: "Execute the plan in PLAN.md"
    context: "A detailed plan document specifying 7 phases: Docker Compose stack, JSONL watcher service, 4 Grafana dashboards, and polish scripts"
    effectiveness: high
    notes: "Claude created 24 files across the entire stack in ~20 minutes, launching 4 parallel sub-agents to generate dashboard JSON simultaneously."
  - prompt: "The dashboard isn't showing token use or cost while work is happening, I think something is wrong. Please debug that"
    context: "Dashboards were rendering but metrics weren't updating in real-time"
    effectiveness: high
    notes: "Claude methodically narrowed from 'is the watcher running?' to 'are counters changing?' to finding two bugs: chokidar v4 dropped polling support, and project labels were derived from cwd instead of file path."
lessonsLearned:
  whatWorked:
    - "Detailed upfront planning produced a correct scaffold on first pass — 24 files, all valid"
    - "Parallel sub-agents for dashboard JSON generation cut what would have been sequential work into 2 minutes"
    - "Having Claude debug its own output worked well — it added debug endpoints, traced through the code, and found the root cause"
    - "Using real JSONL data during planning ensured the parser matched the actual format"
  whatDidnt:
    - "Chokidar v4 silently dropped usePolling and awaitWriteFinish — the watcher appeared to start but never detected changes"
    - "Deriving project name from cwd (which changes mid-session) split one session's data across multiple labels"
    - "Grafana dashboard JSON generated by sub-agents needed datasource UID fixes — string references don't work with provisioned datasources"
  whatIdDoDifferently:
    - "Test file watching with a live session immediately, not just backfill"
    - "Pin datasource UIDs in the provisioning config from the start"
    - "Use a simpler polling-based watcher instead of depending on filesystem event libraries"
costTracking:
  inputTokens: 254
  outputTokens: 16096
  totalCost: 17
  sessions: 3
---

## The Problem

I'd been using Claude Code for a week and had no idea how much it was costing me. The CLI shows per-message token counts, but there's no dashboard, no history, no way to see "I spent $X today across Y sessions." The data exists though — Claude Code writes detailed JSONL files to `~/.claude/projects/` with per-message token counts, model info, and tool usage. And it supports OpenTelemetry for real-time metrics export.

I wanted dashboards that answer: How much am I spending? What's my cost rate right now? How efficient is the prompt cache? Which tools get used most?

## The Architecture

```
Claude Code ──OTLP (gRPC:4317)──> OTEL Collector ──> Prometheus (metrics)
                                        └──────────> Loki (logs/events)

JSONL Watcher ──scrape (:9101)──> Prometheus
(watches ~/.claude/projects/*/*.jsonl)

Prometheus + Loki ──> Grafana (pre-provisioned dashboards)
```

Two data paths feed the same dashboards:

1. **OpenTelemetry** — Claude Code exports real-time metrics (tokens, cost, LOC) via OTLP to an OTEL Collector, which forwards to Prometheus and Loki
2. **JSONL Watcher** — A custom Node.js service watches session files on disk, parses them, computes costs from a pricing table, and exposes Prometheus-format metrics

Everything runs locally: Docker Compose for the infrastructure (OTEL Collector, Prometheus, Loki, Grafana), and the JSONL watcher runs natively on macOS for filesystem access.

## The Build: 50 Minutes, 3 Sessions

The entire project was built in a single sitting across 3 Claude Code sessions. Here's the timeline, broken into 2-minute blocks:

### Session 1: Planning (28 minutes)

| Time | What Happened |
|------|--------------|
| 00:00–02:00 | I described what I wanted: "dashboards to understand my Claude usage with views by minute/hour/day." Claude explored the data sources — JSONL files, OTEL support, Claude Code internals. |
| 02:00–04:00 | Claude reported findings: rich local JSONL data with per-message token counts, streaming message deduplication, and native OTEL export. Presented architecture options. |
| 04:00–06:00 | I chose Grafana + OTEL + file watching. Claude began drafting the plan. |
| 06:00–22:00 | Extended plan generation in plan mode. Claude designed the full architecture: Docker Compose services, JSONL watcher modules, 4 dashboard layouts with specific PromQL queries, and a phased build order. ~16 minutes of thinking. |
| 22:00–26:00 | Claude verified assumptions by reading actual JSONL files. Confirmed the streaming deduplication pattern: same `msg_id` appears multiple times with increasing `output_tokens`. |
| 26:00–28:00 | Plan written to `PLAN.md` and approved. |

### Session 2: Brief Interlude (1 minute)

Quick session to write the plan to a file for the execution session.

### Session 3: Execution (20 minutes)

| Time | What Happened |
|------|--------------|
| 00:00–02:00 | "Execute the plan in PLAN.md." Claude read the plan, checked the empty project directory, created 4 task items, and examined JSONL data format with 9 bash calls to understand the structure. |
| 02:00–04:00 | **Infrastructure blitz.** 7 parallel `Write` calls created Docker Compose, OTEL Collector config, Prometheus config, Loki config, and Grafana provisioning files. Then 6 more `Write` calls for the JSONL watcher TypeScript source (index, watcher, parser, metrics, backfill, pricing). |
| 04:00–06:00 | **Parallel dashboard generation.** Claude launched 4 sub-agents simultaneously, each generating a full Grafana dashboard JSON (~300 lines each). Meanwhile, it created the Makefile, setup.sh, start.sh, and .gitignore. |
| 06:00–08:00 | All 4 dashboard agents completed. `npm install`, TypeScript compilation check (zero errors), and a smoke test: the JSONL watcher backfilled **17 session files (4,781 lines)** and exposed real metrics on `:9101/metrics`. |
| 08:00–10:00 | Added OTEL env vars to `~/.zshrc`. Installed Docker via Homebrew. Hit a `sudo` permission issue (can't run `sudo` from Claude Code). |
| 10:00–14:00 | Fixed Docker Compose by symlinking the plugin to `~/.docker/cli-plugins/`. Started Docker daemon. |
| 14:00–20:00 | **Debugging real-time tracking.** Dashboards showed backfilled data but not live updates. Systematic debugging: verified watcher health → checked file offsets → confirmed counters weren't incrementing → found chokidar v4 silently dropped polling → added 2-second polling fallback → found project labels split across different cwd values → fixed to use file path. |

## What It Cost

| | Tokens | Cost |
|---|---:|---:|
| Input | 254 | $0.004 |
| Output | 16,096 | $1.21 |
| Cache Creation | 302,139 | $5.67 |
| Cache Read | 6,654,764 | $9.98 |
| **Total** | **6,973,253** | **$16.86** |

Cache reads dominate: 95% of all tokens, 59% of total cost. This is because Claude Code sends the full conversation context on every API call, and Anthropic's prompt caching means most of that context is a cache hit at $1.50/MTok instead of $15/MTok. The cache is doing its job.

The planning session cost $5 (28 minutes of thinking), and the execution session cost $12 (20 minutes of building + debugging).

## The Dashboard

![Cost Overview dashboard showing $13.40 total cost, $66.74/hr rate, cumulative cost chart, cost by project breakdown, and 100% cache hit rate](/claude-bootstrap-blog/images/monitoring/01-cost-overview.png)

The Cost Overview dashboard shows:

- **KPIs**: Total cost ($13.40 during this hour), cost rate ($66.74/hr — high because it includes dashboard debugging), active sessions, total tokens
- **Time Series**: Cumulative cost and instantaneous cost rate over time, broken down by model
- **Breakdown**: Cost by project (bar chart showing spend across all my Claude projects) and token type distribution (99% cache reads)
- **Efficiency**: Cache hit rate (100% — prompt caching is working) and cost per prompt ($0.14 average)

Three additional dashboards provide token-level detail, tool usage patterns, and per-session drill-down.

## The Bugs

Two bugs made the dashboards appear broken even though the data was there:

**Bug 1: Chokidar v4 silently dropped `usePolling`.** The JSONL watcher used chokidar to detect file changes. Chokidar v3 had `usePolling` and `awaitWriteFinish` options that made it work reliably with rapidly-written files. Chokidar v4 removed these options without error — the watcher started, said "watching," and never fired a change event. Fix: added a 2-second polling fallback that manually checks all known files.

**Bug 2: Project label derived from `cwd` instead of file path.** Each JSONL line includes a `cwd` field showing where Claude Code was working. I used this to derive the project name. But `cwd` changes as Claude navigates directories (e.g., `cd jsonl-watcher` to run npm). This split one session's data across labels like `claude-monitoring` and `jsonl-watcher`. Fix: derive the project name from the JSONL file's directory path, which is stable.

## The Stack

| Component | Purpose |
|-----------|---------|
| **OTEL Collector** | Receives real-time OTLP from Claude Code, exports to Prometheus + Loki |
| **Prometheus** | Time-series storage for token/cost metrics |
| **Loki** | Log storage for OTEL events (user prompts, API requests, tool results) |
| **Grafana** | 4 pre-provisioned dashboards with template variables |
| **JSONL Watcher** | Node.js/TypeScript service: backfills history, watches for live changes, exposes `/metrics` |

Total files created: 24. `make up` starts everything. `make down` stops it.

## Recursive Irony

The monitoring dashboard was watching itself being built. As I debugged the real-time tracking bugs, the dashboard's cost counter was incrementing with each API call I made to debug it. By the time I fixed the second bug, the dashboard showed $17 spent — which was the cost of building the dashboard that showed me it cost $17.
